{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End to End Evaluation for PVNet\n",
    "This notebook provides steps to evaluate PVNet on a same dataset that is being used for Mask R-CNN evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Simulated script arguments\n",
    "sys.argv = ['script_name', '--det', 'example_det', '--type', 'example_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model: data/model/pvnet/mainshell/30.pth\n",
      "Load model: data/model/pvnet/topshell/50.pth\n",
      "Load model: data/model/pvnet/insert_mold/25.pth\n"
     ]
    }
   ],
   "source": [
    "from lib.config import cfgs\n",
    "from cobot_pipeline import make_and_load_pvnet\n",
    "\n",
    "# Configs/Models in the order 0: mainshell, 1: topshell, 2: insert_mold \n",
    "pvnets = tuple([make_and_load_pvnet(c) for c in cfgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0', '1', '2'])\n",
      "dict_keys(['camera_K', 'camera_pose_in_world', 'instances'])\n",
      "dict_keys(['instance_id', 'category_id', 'cropped_rgb', 'cropped_mask', 'uv', 'pose_in_cam', 'pose_in_world'])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dataset_path = \"/pvnet/data/FIT/end2end\"\n",
    "pvnet_base_dir = os.path.join(dataset_path, \"pvnet\")\n",
    "pvnet_annotation_path = os.path.join(pvnet_base_dir, \"pvnet.json\")\n",
    "maskrcnn_csv_path = os.path.join(pvnet_base_dir, \"eval_output_for_pvnet.csv\")\n",
    "\n",
    "with open(pvnet_annotation_path, 'r') as file:\n",
    "    pvnet_annotation = json.load(file)\n",
    "    \n",
    "# Example of pvnet annotation for each instance\n",
    "print(pvnet_annotation.keys())\n",
    "print(pvnet_annotation['0'].keys())\n",
    "print(pvnet_annotation['0']['instances'][0].keys())\n",
    "print(pvnet_annotation['0']['instances'][0]['category_id']) #COCO format: 1-mainshell, 2-topshell, 3-insert_mold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive detected: Instance -1, Category 1\n",
      "False Positive detected: Instance 30, Category 1\n",
      "======================================================================\n",
      "Summary Of Evaluation On GT Cropping\n",
      "======================================================================\n",
      "Category: mainshell\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 2.29 mm, Std = 3.97 mm\n",
      "    Translation Error (Y): Mean = 1.48 mm, Std = 2.22 mm\n",
      "    Translation Error (Z): Mean = 149.93 mm, Std = 221.88 mm\n",
      "    Angular Error (deg): Mean = 16.21, Std = 23.81\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 2.29 mm, Std = 3.97 mm\n",
      "    Translation Error (Y): Mean = 1.48 mm, Std = 2.22 mm\n",
      "    Translation Error (Z): Mean = 9.22 mm, Std = 0.76 mm\n",
      "    Angular Error (deg): Mean = 10.16, Std = 26.29\n",
      "    Valid Examples: 21\n",
      "Category: topshell\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 1.32 mm, Std = 1.11 mm\n",
      "    Translation Error (Y): Mean = 1.44 mm, Std = 1.01 mm\n",
      "    Translation Error (Z): Mean = 90.94 mm, Std = 34.17 mm\n",
      "    Angular Error (deg): Mean = 3.97, Std = 1.96\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 1.32 mm, Std = 1.11 mm\n",
      "    Translation Error (Y): Mean = 1.44 mm, Std = 1.01 mm\n",
      "    Translation Error (Z): Mean = 9.02 mm, Std = 1.04 mm\n",
      "    Angular Error (deg): Mean = 0.96, Std = 0.86\n",
      "    Valid Examples: 21\n",
      "Category: insert_mold\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 0.76 mm, Std = 1.19 mm\n",
      "    Translation Error (Y): Mean = 1.17 mm, Std = 2.60 mm\n",
      "    Translation Error (Z): Mean = 88.07 mm, Std = 206.80 mm\n",
      "    Angular Error (deg): Mean = 5.89, Std = 5.89\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 0.76 mm, Std = 1.19 mm\n",
      "    Translation Error (Y): Mean = 1.17 mm, Std = 2.60 mm\n",
      "    Translation Error (Z): Mean = 9.74 mm, Std = 1.17 mm\n",
      "    Angular Error (deg): Mean = 5.84, Std = 19.12\n",
      "    Valid Examples: 21\n",
      "======================================================================\n",
      "Summary Of Evaluation On Mask-R-CNN-Predicted Cropping\n",
      "======================================================================\n",
      "Category: mainshell\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 1.89 mm, Std = 2.56 mm\n",
      "    Translation Error (Y): Mean = 1.35 mm, Std = 1.35 mm\n",
      "    Translation Error (Z): Mean = 127.66 mm, Std = 150.83 mm\n",
      "    Angular Error (deg): Mean = 17.20, Std = 24.95\n",
      "    Valid Examples: 20\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 1.89 mm, Std = 2.56 mm\n",
      "    Translation Error (Y): Mean = 1.35 mm, Std = 1.35 mm\n",
      "    Translation Error (Z): Mean = 9.26 mm, Std = 0.85 mm\n",
      "    Angular Error (deg): Mean = 10.20, Std = 27.06\n",
      "    Valid Examples: 20\n",
      "Category: topshell\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 1.38 mm, Std = 1.15 mm\n",
      "    Translation Error (Y): Mean = 1.45 mm, Std = 1.06 mm\n",
      "    Translation Error (Z): Mean = 95.02 mm, Std = 29.91 mm\n",
      "    Angular Error (deg): Mean = 3.63, Std = 1.80\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 1.38 mm, Std = 1.15 mm\n",
      "    Translation Error (Y): Mean = 1.45 mm, Std = 1.06 mm\n",
      "    Translation Error (Z): Mean = 8.99 mm, Std = 1.02 mm\n",
      "    Angular Error (deg): Mean = 1.11, Std = 1.02\n",
      "    Valid Examples: 21\n",
      "Category: insert_mold\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 0.79 mm, Std = 0.65 mm\n",
      "    Translation Error (Y): Mean = 0.99 mm, Std = 1.19 mm\n",
      "    Translation Error (Z): Mean = 70.57 mm, Std = 82.07 mm\n",
      "    Angular Error (deg): Mean = 5.03, Std = 4.37\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 0.79 mm, Std = 0.65 mm\n",
      "    Translation Error (Y): Mean = 0.99 mm, Std = 1.19 mm\n",
      "    Translation Error (Z): Mean = 9.56 mm, Std = 1.06 mm\n",
      "    Angular Error (deg): Mean = 5.64, Std = 19.12\n",
      "    Valid Examples: 21\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation\n",
    "from lib.datasets.transforms import make_transforms\n",
    "from lib.utils.pvnet import pvnet_pose_utils\n",
    "from mrcnn.stable_poses_est import construct_T_stable_from_T_est\n",
    "from cobot_pvnet import draw_axis\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, pvnet_annotation, categories, pvnet_models, cfgs, base_dir, maskrcnn_csv_path):\n",
    "        self.pvnet_annotation = pvnet_annotation\n",
    "        self.categories = categories\n",
    "        self.pvnet_models = pvnet_models\n",
    "        self.cfgs = cfgs\n",
    "        self.base_dir = base_dir\n",
    "        self.maskrcnn_csv_path = maskrcnn_csv_path\n",
    "        self.dataset_dir = os.path.dirname(base_dir)\n",
    "        self.cropping_size = 128\n",
    "        self.instance_miss_cnt = 0\n",
    "        self.gt_results = {\n",
    "            category: {\n",
    "                \"raw\": {\"translation_error\": {\"x\": [], \"y\": [], \"z\": []}, \"angular_error\": []},\n",
    "                \"refined\": {\"translation_error\": {\"x\": [], \"y\": [], \"z\": []}, \"angular_error\": []},\n",
    "                \"valid_count\": {\"raw\": 0, \"refined\": 0},  # Valid example counter\n",
    "                \"visualized\": 0,  # Counter for visualized examples\n",
    "            }\n",
    "            for category in categories\n",
    "        }\n",
    "        self.maskrcnn_results = {\n",
    "            category: {\n",
    "                \"raw\": {\"translation_error\": {\"x\": [], \"y\": [], \"z\": []}, \"angular_error\": []},\n",
    "                \"refined\": {\"translation_error\": {\"x\": [], \"y\": [], \"z\": []}, \"angular_error\": []},\n",
    "                \"valid_count\": {\"raw\": 0, \"refined\": 0},  # Valid example counter\n",
    "                \"visualized\": 0,  # Counter for visualized examples\n",
    "            }\n",
    "            for category in categories\n",
    "        }\n",
    "\n",
    "    def run_inference(self, pvnet, cfg, image, K_cam):\n",
    "        pvnet.eval()\n",
    "        transform = make_transforms(cfg, is_train=False)\n",
    "        processed_image, _, _ = transform(image)\n",
    "        processed_image = np.array(processed_image).astype(np.float32)\n",
    "\n",
    "        input_tensor = torch.from_numpy(processed_image).unsqueeze(0).cuda().float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pvnet_output = pvnet(input_tensor)\n",
    "\n",
    "        kpt_3d = np.concatenate([cfg.fps_3d, [cfg.center_3d]], axis=0)\n",
    "        kpt_2d = pvnet_output['kpt_2d'][0].detach().cpu().numpy()\n",
    "        pose_pred = pvnet_pose_utils.pnp(kpt_3d, kpt_2d, K_cam)\n",
    "\n",
    "        return np.c_[pose_pred.T, np.array([0, 0, 0, 1])].T\n",
    "\n",
    "    def compute_errors(self, pose_pred, pose_gt):\n",
    "        t_pred = pose_pred[:3, 3]\n",
    "        t_gt = pose_gt[:3, 3]\n",
    "        translation_error = {\n",
    "            \"x\": np.abs(t_pred[0] - t_gt[0]),\n",
    "            \"y\": np.abs(t_pred[1] - t_gt[1]),\n",
    "            \"z\": np.abs(t_pred[2] - t_gt[2]),\n",
    "        }\n",
    "\n",
    "        R_pred = pose_pred[:3, :3]\n",
    "        R_gt = pose_gt[:3, :3]\n",
    "        R_diff = R_pred @ R_gt.T\n",
    "        trace = np.trace(R_diff)\n",
    "        trace = min(3, max(-1, trace))\n",
    "        angular_error = np.rad2deg(np.arccos((trace - 1) / 2))\n",
    "\n",
    "        return translation_error, angular_error\n",
    "\n",
    "    def add_to_gt_results(self, category, pose_pred, pose_gt, prediction_type):\n",
    "        translation_error, angular_error = self.compute_errors(pose_pred, pose_gt)\n",
    "\n",
    "        # if angular_error > 10:\n",
    "        #     return False  # Mark as outlier\n",
    "\n",
    "        for axis in [\"x\", \"y\", \"z\"]:\n",
    "            self.gt_results[category][prediction_type][\"translation_error\"][axis].append(translation_error[axis])\n",
    "\n",
    "        self.gt_results[category][prediction_type][\"angular_error\"].append(angular_error)\n",
    "        self.gt_results[category][\"valid_count\"][prediction_type] += 1\n",
    "\n",
    "        return True  # Mark as valid\n",
    "\n",
    "    def add_to_maskrcnn_results(self, category, pose_pred, pose_gt, prediction_type):\n",
    "        translation_error, angular_error = self.compute_errors(pose_pred, pose_gt)\n",
    "\n",
    "        # if angular_error > 10:\n",
    "        #     return False  # Mark as outlier\n",
    "\n",
    "        for axis in [\"x\", \"y\", \"z\"]:\n",
    "            self.maskrcnn_results[category][prediction_type][\"translation_error\"][axis].append(translation_error[axis])\n",
    "\n",
    "        self.maskrcnn_results[category][prediction_type][\"angular_error\"].append(angular_error)\n",
    "        self.maskrcnn_results[category][\"valid_count\"][prediction_type] += 1\n",
    "\n",
    "        return True  # Mark as valid\n",
    "    \n",
    "    def plot_predictions(self, image_rgb, gt, raw_prediction, refined_prediction, K):\n",
    "        gt_img_overlay = draw_axis(image_rgb, gt[:3, :3], gt[:3, 3], K)\n",
    "        raw_img_overlay = draw_axis(image_rgb, raw_prediction[:3, :3], raw_prediction[:3, 3], K)\n",
    "        # refined_img_overlay = draw_axis(image_rgb, refined_prediction[:3, :3], refined_prediction[:3, 3], K)\n",
    "        # For the purpose of visualization, make sure the origin doesn't shift away from center of object\n",
    "        refined_img_overlay = draw_axis(image_rgb, refined_prediction[:3, :3], raw_prediction[:3, 3], K)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "        axes[0].imshow(image_rgb)\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "\n",
    "        axes[1].imshow(gt_img_overlay)\n",
    "        axes[1].axis(\"off\")\n",
    "        axes[1].set_title(\"Ground Truth\")\n",
    "        \n",
    "        axes[2].imshow(raw_img_overlay)\n",
    "        axes[2].axis(\"off\")\n",
    "        axes[2].set_title(\"Raw Prediction\")\n",
    "\n",
    "        axes[3].imshow(refined_img_overlay)\n",
    "        axes[3].axis(\"off\")\n",
    "        axes[3].set_title(\"Refined Prediction\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def evaluate_gt_cropping(self):\n",
    "        for image_id, image_data in self.pvnet_annotation.items():\n",
    "            camera_K = np.array(image_data['camera_K'])\n",
    "            camera_pose_in_world = np.array(image_data['camera_pose_in_world'])\n",
    "\n",
    "            for instance in image_data['instances']:\n",
    "                category_id = instance[\"category_id\"]\n",
    "                category = self.categories[category_id - 1]\n",
    "                cropped_rgb_path = os.path.join(self.base_dir, instance[\"cropped_rgb\"])\n",
    "                if not os.path.exists(cropped_rgb_path):\n",
    "                    print(f\"Image path does not exist: {cropped_rgb_path}\")\n",
    "                    continue\n",
    "\n",
    "                image = cv2.imread(cropped_rgb_path)\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                K = camera_K.copy()\n",
    "                uv = instance[\"uv\"]\n",
    "                K[0, 2] += self.cropping_size // 2 - uv[0]\n",
    "                K[1, 2] += self.cropping_size // 2 - uv[1]\n",
    "\n",
    "                pose_gt = np.array(instance[\"pose_in_cam\"])\n",
    "                raw_prediction = self.run_inference(self.pvnet_models[category_id - 1], self.cfgs[category_id - 1], image_rgb, K)\n",
    "\n",
    "                T_cam_in_world = camera_pose_in_world.copy()\n",
    "                T_pred_in_world = T_cam_in_world @ raw_prediction\n",
    "                T_stable_in_world = construct_T_stable_from_T_est(T_pred_in_world, category_id - 1)\n",
    "                refined_prediction = np.linalg.inv(T_cam_in_world) @ T_stable_in_world\n",
    "                refined_prediction[0, 3] = raw_prediction[0, 3]\n",
    "                refined_prediction[1, 3] = raw_prediction[1, 3]\n",
    "\n",
    "                raw_valid = self.add_to_gt_results(category, raw_prediction, pose_gt, prediction_type=\"raw\")\n",
    "                refined_valid = self.add_to_gt_results(category, refined_prediction, pose_gt, prediction_type=\"refined\")\n",
    "\n",
    "                if refined_valid and self.gt_results[category][\"visualized\"] < 1:\n",
    "#                     self.plot_predictions(image_rgb, pose_gt, raw_prediction, refined_prediction, K)\n",
    "                    self.gt_results[category][\"visualized\"] += 1\n",
    "\n",
    "    def evaluate_maskrcnn_prediction(self):\n",
    "        maskrcnn_output_dir = {}\n",
    "\n",
    "        # Load Mask R-CNN CSV predictions\n",
    "        with open(self.maskrcnn_csv_path, mode='r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Skip header row\n",
    "            for row in reader:\n",
    "                gtAnnsIds = int(row[0])\n",
    "                imgId = int(row[1])\n",
    "                predcatId = int(row[2])\n",
    "                status = row[3]  # 'TP', 'FP', 'FN'\n",
    "                bbox_cent = eval(row[4])  # Convert '(x, y)' string to tuple\n",
    "\n",
    "                if imgId not in maskrcnn_output_dir:\n",
    "                    maskrcnn_output_dir[imgId] = []\n",
    "\n",
    "                maskrcnn_output_dir[imgId].append({\n",
    "                    \"instance_id\": gtAnnsIds,\n",
    "                    \"pred_category_id\": predcatId,\n",
    "                    \"TP/FP/FN\": status,\n",
    "                    \"uv\": bbox_cent\n",
    "                })\n",
    "\n",
    "        # Iterate through Mask R-CNN output\n",
    "        for imgId, instances in maskrcnn_output_dir.items():\n",
    "            full_2k_img_path = os.path.join(self.dataset_dir, \"images\", f\"{imgId:06}.png\")\n",
    "            if not os.path.exists(full_2k_img_path):\n",
    "                print(f\"Image path does not exist: {full_2k_img_path}\")\n",
    "                continue\n",
    "\n",
    "            full_2k_img = cv2.imread(full_2k_img_path)\n",
    "            full_2k_img = cv2.cvtColor(full_2k_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            camera_K = self.pvnet_annotation[str(imgId)]['camera_K']\n",
    "            camera_pose_in_world = self.pvnet_annotation[str(imgId)]['camera_pose_in_world']\n",
    "\n",
    "            for instance in instances:\n",
    "                instance_id = instance['instance_id']\n",
    "                pred_category_id = instance['pred_category_id']\n",
    "                status = instance['TP/FP/FN']\n",
    "                uv = instance['uv']\n",
    "\n",
    "                if status == \"TP\":\n",
    "                    cropped_img = full_2k_img[\n",
    "                        max(uv[1] - self.cropping_size // 2, 0):min(uv[1] + self.cropping_size // 2, full_2k_img.shape[0]),\n",
    "                        max(uv[0] - self.cropping_size // 2, 0):min(uv[0] + self.cropping_size // 2, full_2k_img.shape[1])\n",
    "                    ]\n",
    "\n",
    "                    K = np.array(camera_K)\n",
    "                    K[0, 2] += self.cropping_size // 2 - uv[0]\n",
    "                    K[1, 2] += self.cropping_size // 2 - uv[1]\n",
    "\n",
    "                    pose_gt = self.find_gt_pose(instance_id, pred_category_id, imgId)\n",
    "                    if pose_gt is None:\n",
    "                        print(f\"No GT pose found for Instance {instance_id}\")\n",
    "                        continue\n",
    "\n",
    "                    # Run PVNet inference\n",
    "                    raw_prediction = self.run_inference(self.pvnet_models[pred_category_id - 1], \n",
    "                                                         self.cfgs[pred_category_id - 1], \n",
    "                                                         cropped_img, K)\n",
    "                    \n",
    "                    T_cam_in_world = np.array(camera_pose_in_world)\n",
    "                    T_pred_in_world = T_cam_in_world @ raw_prediction\n",
    "                    T_stable_in_world = construct_T_stable_from_T_est(T_pred_in_world, pred_category_id - 1)\n",
    "                    refined_prediction = np.linalg.inv(T_cam_in_world) @ T_stable_in_world\n",
    "                    refined_prediction[0, 3] = raw_prediction[0, 3]\n",
    "                    refined_prediction[1, 3] = raw_prediction[1, 3]\n",
    "\n",
    "                    # Add results to evaluation\n",
    "                    raw_valid = self.add_to_maskrcnn_results(self.categories[pred_category_id - 1], \n",
    "                                                       raw_prediction, pose_gt, prediction_type=\"raw\")\n",
    "                    refined_valid = self.add_to_maskrcnn_results(self.categories[pred_category_id - 1], \n",
    "                                                           refined_prediction, pose_gt, prediction_type=\"refined\")\n",
    "\n",
    "                    if refined_valid and self.maskrcnn_results[self.categories[pred_category_id - 1]][\"visualized\"] < 1:\n",
    "#                         self.plot_predictions(cropped_img, pose_gt, raw_prediction, refined_prediction, K)\n",
    "                        self.maskrcnn_results[self.categories[pred_category_id - 1]][\"visualized\"] += 1\n",
    "\n",
    "                elif status == \"FN\":\n",
    "                    print(f\"Instance {instance_id} was not detected by Mask R-CNN\")\n",
    "                    self.instance_miss_cnt += 1\n",
    "\n",
    "                elif status == \"FP\":\n",
    "                    print(f\"False Positive detected: Instance {instance_id}, Category {pred_category_id}\")\n",
    "\n",
    "    def find_gt_pose(self, instance_id, pred_category_id, imgId):\n",
    "        \"\"\"\n",
    "        Find the ground truth pose for a given instance ID.\n",
    "        \"\"\"\n",
    "        for instance in self.pvnet_annotation[str(imgId)]['instances']:\n",
    "            if instance[\"category_id\"] == pred_category_id and instance[\"instance_id\"] == instance_id:\n",
    "                return np.array(instance[\"pose_in_cam\"])\n",
    "        return None\n",
    "\n",
    "                \n",
    "    def summarize(self):\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Summary Of Evaluation On GT Cropping\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        for category, stats in self.gt_results.items():\n",
    "            print(f\"Category: {category}\")\n",
    "            for pred_type, results in stats.items():\n",
    "                if pred_type in [\"valid_count\", \"visualized\"]:\n",
    "                    continue\n",
    "                trans_errors = results[\"translation_error\"]\n",
    "                angular_errors = np.array(results[\"angular_error\"])\n",
    "\n",
    "                if len(trans_errors[\"x\"]) > 0:\n",
    "                    trans_means = {axis: np.mean(np.array(trans_errors[axis]) * 1000) for axis in [\"x\", \"y\", \"z\"]}\n",
    "                    trans_stds = {axis: np.std(np.array(trans_errors[axis]) * 1000) for axis in [\"x\", \"y\", \"z\"]}\n",
    "                    angular_mean = np.mean(angular_errors)\n",
    "                    angular_std = np.std(angular_errors)\n",
    "\n",
    "                    print(f\"  {pred_type.capitalize()} Prediction:\")\n",
    "                    for axis in [\"x\", \"y\", \"z\"]:\n",
    "                        print(f\"    Translation Error ({axis.upper()}): Mean = {trans_means[axis]:.2f} mm, Std = {trans_stds[axis]:.2f} mm\")\n",
    "                    print(f\"    Angular Error (deg): Mean = {angular_mean:.2f}, Std = {angular_std:.2f}\")\n",
    "                    print(f\"    Valid Examples: {stats['valid_count'][pred_type]}\")\n",
    "                else:\n",
    "                    print(f\"  {pred_type.capitalize()} Prediction: No valid instances.\")\n",
    "\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Summary Of Evaluation On Mask-R-CNN-Predicted Cropping\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        for category, stats in self.maskrcnn_results.items():\n",
    "            print(f\"Category: {category}\")\n",
    "            for pred_type, results in stats.items():\n",
    "                if pred_type in [\"valid_count\", \"visualized\"]:\n",
    "                    continue\n",
    "                trans_errors = results[\"translation_error\"]\n",
    "                angular_errors = np.array(results[\"angular_error\"])\n",
    "\n",
    "                if len(trans_errors[\"x\"]) > 0:\n",
    "                    trans_means = {axis: np.mean(np.array(trans_errors[axis]) * 1000) for axis in [\"x\", \"y\", \"z\"]}\n",
    "                    trans_stds = {axis: np.std(np.array(trans_errors[axis]) * 1000) for axis in [\"x\", \"y\", \"z\"]}\n",
    "                    angular_mean = np.mean(angular_errors)\n",
    "                    angular_std = np.std(angular_errors)\n",
    "\n",
    "                    print(f\"  {pred_type.capitalize()} Prediction:\")\n",
    "                    for axis in [\"x\", \"y\", \"z\"]:\n",
    "                        print(f\"    Translation Error ({axis.upper()}): Mean = {trans_means[axis]:.2f} mm, Std = {trans_stds[axis]:.2f} mm\")\n",
    "                    print(f\"    Angular Error (deg): Mean = {angular_mean:.2f}, Std = {angular_std:.2f}\")\n",
    "                    print(f\"    Valid Examples: {stats['valid_count'][pred_type]}\")\n",
    "                else:\n",
    "                    print(f\"  {pred_type.capitalize()} Prediction: No valid instances.\")\n",
    "\n",
    "categories = [\"mainshell\", \"topshell\", \"insert_mold\"]\n",
    "evaluator = Evaluator(pvnet_annotation, categories, pvnets, cfgs, pvnet_base_dir, maskrcnn_csv_path)\n",
    "evaluator.evaluate_maskrcnn_prediction()\n",
    "evaluator.evaluate_gt_cropping()\n",
    "evaluator.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Summary of Evaluation on GT Cropping\n",
      "======================================================================\n",
      "Category: mainshell\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 1.86 mm, Std = 2.82 mm\n",
      "    Translation Error (Y): Mean = 1.31 mm, Std = 1.55 mm\n",
      "    Translation Error (Z): Mean = 137.95 mm, Std = 187.45 mm\n",
      "    Angular Error (deg): Mean = 15.85, Std = 24.22\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 1.86 mm, Std = 2.82 mm\n",
      "    Translation Error (Y): Mean = 1.31 mm, Std = 1.55 mm\n",
      "    Translation Error (Z): Mean = 9.14 mm, Std = 0.92 mm\n",
      "    Angular Error (deg): Mean = 14.12, Std = 31.85\n",
      "    Valid Examples: 21\n",
      "Category: topshell\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 1.38 mm, Std = 1.23 mm\n",
      "    Translation Error (Y): Mean = 1.40 mm, Std = 1.04 mm\n",
      "    Translation Error (Z): Mean = 92.93 mm, Std = 32.97 mm\n",
      "    Angular Error (deg): Mean = 3.84, Std = 1.74\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 1.38 mm, Std = 1.23 mm\n",
      "    Translation Error (Y): Mean = 1.40 mm, Std = 1.04 mm\n",
      "    Translation Error (Z): Mean = 9.06 mm, Std = 0.95 mm\n",
      "    Angular Error (deg): Mean = 1.00, Std = 1.01\n",
      "    Valid Examples: 21\n",
      "Category: insert_mold\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 0.81 mm, Std = 1.32 mm\n",
      "    Translation Error (Y): Mean = 1.26 mm, Std = 2.98 mm\n",
      "    Translation Error (Z): Mean = 95.41 mm, Std = 240.21 mm\n",
      "    Angular Error (deg): Mean = 5.41, Std = 5.96\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 0.81 mm, Std = 1.32 mm\n",
      "    Translation Error (Y): Mean = 1.26 mm, Std = 2.98 mm\n",
      "    Translation Error (Z): Mean = 9.74 mm, Std = 1.26 mm\n",
      "    Angular Error (deg): Mean = 5.56, Std = 15.78\n",
      "    Valid Examples: 21\n",
      "======================================================================\n",
      "Summary of Evaluation on Mask-R-CNN Predicted Cropping\n",
      "======================================================================\n",
      "Category: mainshell\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 2.01 mm, Std = 2.95 mm\n",
      "    Translation Error (Y): Mean = 1.54 mm, Std = 2.00 mm\n",
      "    Translation Error (Z): Mean = 148.63 mm, Std = 215.29 mm\n",
      "    Angular Error (deg): Mean = 20.72, Std = 33.07\n",
      "    Valid Examples: 20\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 2.01 mm, Std = 2.95 mm\n",
      "    Translation Error (Y): Mean = 1.54 mm, Std = 2.00 mm\n",
      "    Translation Error (Z): Mean = 9.06 mm, Std = 0.88 mm\n",
      "    Angular Error (deg): Mean = 15.40, Std = 32.81\n",
      "    Valid Examples: 20\n",
      "Category: topshell\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 1.29 mm, Std = 1.03 mm\n",
      "    Translation Error (Y): Mean = 1.41 mm, Std = 1.02 mm\n",
      "    Translation Error (Z): Mean = 89.16 mm, Std = 31.62 mm\n",
      "    Angular Error (deg): Mean = 3.80, Std = 1.78\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 1.29 mm, Std = 1.03 mm\n",
      "    Translation Error (Y): Mean = 1.41 mm, Std = 1.02 mm\n",
      "    Translation Error (Z): Mean = 9.04 mm, Std = 1.00 mm\n",
      "    Angular Error (deg): Mean = 1.19, Std = 1.02\n",
      "    Valid Examples: 21\n",
      "Category: insert_mold\n",
      "  Raw Prediction:\n",
      "    Translation Error (X): Mean = 0.74 mm, Std = 0.68 mm\n",
      "    Translation Error (Y): Mean = 0.76 mm, Std = 0.63 mm\n",
      "    Translation Error (Z): Mean = 57.03 mm, Std = 30.90 mm\n",
      "    Angular Error (deg): Mean = 5.36, Std = 4.79\n",
      "    Valid Examples: 21\n",
      "  Refined Prediction:\n",
      "    Translation Error (X): Mean = 0.74 mm, Std = 0.68 mm\n",
      "    Translation Error (Y): Mean = 0.76 mm, Std = 0.63 mm\n",
      "    Translation Error (Z): Mean = 9.54 mm, Std = 1.08 mm\n",
      "    Angular Error (deg): Mean = 4.34, Std = 15.62\n",
      "    Valid Examples: 21\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation\n",
    "from lib.datasets.transforms import make_transforms\n",
    "from lib.utils.pvnet import pvnet_pose_utils\n",
    "from mrcnn.stable_poses_est import construct_T_stable_from_T_est\n",
    "from cobot_pvnet import draw_axis\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, pvnet_annotation, categories, pvnet_models, cfgs, base_dir, maskrcnn_csv_path):\n",
    "        self.pvnet_annotation = pvnet_annotation\n",
    "        self.categories = categories\n",
    "        self.pvnet_models = pvnet_models\n",
    "        self.cfgs = cfgs\n",
    "        self.base_dir = base_dir\n",
    "        self.maskrcnn_csv_path = maskrcnn_csv_path\n",
    "        self.dataset_dir = os.path.dirname(base_dir)\n",
    "        self.cropping_size = 128\n",
    "        self.instance_miss_cnt = 0\n",
    "\n",
    "        # Initialize results structure\n",
    "        self.results = {\n",
    "            \"GT\": {\n",
    "                category: self.initialize_results() for category in categories\n",
    "            },\n",
    "            \"MaskRCNN\": {\n",
    "                category: self.initialize_results() for category in categories\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def initialize_results(self):\n",
    "        \"\"\"Initialize the results structure for each category.\"\"\"\n",
    "        return {\n",
    "            \"raw\": {\"translation_error\": {\"x\": [], \"y\": [], \"z\": []}, \"angular_error\": []},\n",
    "            \"refined\": {\"translation_error\": {\"x\": [], \"y\": [], \"z\": []}, \"angular_error\": []},\n",
    "            \"valid_count\": {\"raw\": 0, \"refined\": 0},\n",
    "            \"visualized\": 0,\n",
    "        }\n",
    "\n",
    "    def run_inference(self, pvnet, cfg, image, K_cam):\n",
    "        \"\"\"Run PVNet inference.\"\"\"\n",
    "        pvnet.eval()\n",
    "        transform = make_transforms(cfg, is_train=False)\n",
    "        processed_image, _, _ = transform(image)\n",
    "        processed_image = np.array(processed_image).astype(np.float32)\n",
    "\n",
    "        input_tensor = torch.from_numpy(processed_image).unsqueeze(0).cuda().float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pvnet_output = pvnet(input_tensor)\n",
    "\n",
    "        kpt_3d = np.concatenate([cfg.fps_3d, [cfg.center_3d]], axis=0)\n",
    "        kpt_2d = pvnet_output['kpt_2d'][0].detach().cpu().numpy()\n",
    "        pose_pred = pvnet_pose_utils.pnp(kpt_3d, kpt_2d, K_cam)\n",
    "\n",
    "        return np.c_[pose_pred.T, np.array([0, 0, 0, 1])].T\n",
    "\n",
    "    def compute_errors(self, pose_pred, pose_gt):\n",
    "        \"\"\"Compute translation and angular errors.\"\"\"\n",
    "        t_pred = pose_pred[:3, 3]\n",
    "        t_gt = pose_gt[:3, 3]\n",
    "        translation_error = {\n",
    "            \"x\": np.abs(t_pred[0] - t_gt[0]),\n",
    "            \"y\": np.abs(t_pred[1] - t_gt[1]),\n",
    "            \"z\": np.abs(t_pred[2] - t_gt[2]),\n",
    "        }\n",
    "\n",
    "        R_pred = pose_pred[:3, :3]\n",
    "        R_gt = pose_gt[:3, :3]\n",
    "        R_diff = R_pred @ R_gt.T\n",
    "        trace = np.trace(R_diff)\n",
    "        trace = min(3, max(-1, trace))\n",
    "        angular_error = np.rad2deg(np.arccos((trace - 1) / 2))\n",
    "\n",
    "        return translation_error, angular_error\n",
    "\n",
    "    def add_to_results(self, method, category, pose_pred, pose_gt, prediction_type):\n",
    "        \"\"\"Add errors to results.\"\"\"\n",
    "        translation_error, angular_error = self.compute_errors(pose_pred, pose_gt)\n",
    "        for axis in [\"x\", \"y\", \"z\"]:\n",
    "            self.results[method][category][prediction_type][\"translation_error\"][axis].append(translation_error[axis])\n",
    "\n",
    "        self.results[method][category][prediction_type][\"angular_error\"].append(angular_error)\n",
    "        self.results[method][category][\"valid_count\"][prediction_type] += 1\n",
    "\n",
    "    def evaluate_gt_cropping(self):\n",
    "        \"\"\"Evaluate using GT annotations.\"\"\"\n",
    "        for image_id, image_data in self.pvnet_annotation.items():\n",
    "            camera_K = np.array(image_data['camera_K'])\n",
    "            camera_pose_in_world = np.array(image_data['camera_pose_in_world'])\n",
    "\n",
    "            for instance in image_data['instances']:\n",
    "                category_id = instance[\"category_id\"]\n",
    "                category = self.categories[category_id - 1]\n",
    "                cropped_rgb_path = os.path.join(self.base_dir, instance[\"cropped_rgb\"])\n",
    "                if not os.path.exists(cropped_rgb_path):\n",
    "                    print(f\"Image path does not exist: {cropped_rgb_path}\")\n",
    "                    continue\n",
    "\n",
    "                image = cv2.imread(cropped_rgb_path)\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                K = camera_K.copy()\n",
    "                uv = instance[\"uv\"]\n",
    "                K[0, 2] += self.cropping_size // 2 - uv[0]\n",
    "                K[1, 2] += self.cropping_size // 2 - uv[1]\n",
    "\n",
    "                pose_gt = np.array(instance[\"pose_in_cam\"])\n",
    "                raw_prediction = self.run_inference(self.pvnet_models[category_id - 1], self.cfgs[category_id - 1], image_rgb, K)\n",
    "\n",
    "                T_cam_in_world = camera_pose_in_world.copy()\n",
    "                T_pred_in_world = T_cam_in_world @ raw_prediction\n",
    "                T_stable_in_world = construct_T_stable_from_T_est(T_pred_in_world, category_id - 1)\n",
    "                refined_prediction = np.linalg.inv(T_cam_in_world) @ T_stable_in_world\n",
    "                refined_prediction[0, 3] = raw_prediction[0, 3]\n",
    "                refined_prediction[1, 3] = raw_prediction[1, 3]\n",
    "\n",
    "                self.add_to_results(\"GT\", category, raw_prediction, pose_gt, prediction_type=\"raw\")\n",
    "                self.add_to_results(\"GT\", category, refined_prediction, pose_gt, prediction_type=\"refined\")\n",
    "\n",
    "    def evaluate_maskrcnn_prediction(self):\n",
    "        \"\"\"Evaluate using Mask R-CNN predictions.\"\"\"\n",
    "        maskrcnn_output = self.load_maskrcnn_output()\n",
    "\n",
    "        for imgId, instances in maskrcnn_output.items():\n",
    "            full_img_path = os.path.join(self.dataset_dir, \"images\", f\"{imgId:06}.png\")\n",
    "            if not os.path.exists(full_img_path):\n",
    "                print(f\"Image path does not exist: {full_img_path}\")\n",
    "                continue\n",
    "\n",
    "            full_img = cv2.imread(full_img_path)\n",
    "            full_img = cv2.cvtColor(full_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            camera_K = np.array(self.pvnet_annotation[str(imgId)]['camera_K'])\n",
    "            camera_pose_in_world = self.pvnet_annotation[str(imgId)]['camera_pose_in_world']\n",
    "\n",
    "            for instance in instances:\n",
    "                if instance[\"TP/FP/FN\"] != \"TP\":\n",
    "                    continue\n",
    "\n",
    "                cropped_img = self.crop_image(full_img, instance[\"uv\"])\n",
    "                category = self.categories[instance[\"pred_category_id\"] - 1]\n",
    "\n",
    "                pose_gt = self.find_gt_pose(instance, imgId)\n",
    "                if pose_gt is None:\n",
    "                    print(f\"No GT pose found for Instance {instance['instance_id']}\")\n",
    "                    continue\n",
    "\n",
    "                K = camera_K.copy()\n",
    "                uv = instance[\"uv\"]\n",
    "                K[0, 2] += self.cropping_size // 2 - uv[0]\n",
    "                K[1, 2] += self.cropping_size // 2 - uv[1]\n",
    "                    \n",
    "                raw_prediction = self.run_inference(self.pvnet_models[instance[\"pred_category_id\"] - 1], \n",
    "                                                     self.cfgs[instance[\"pred_category_id\"] - 1], \n",
    "                                                     cropped_img, K)\n",
    "\n",
    "                T_cam_in_world = np.array(camera_pose_in_world)\n",
    "                T_pred_in_world = T_cam_in_world @ raw_prediction\n",
    "                T_stable_in_world = construct_T_stable_from_T_est(T_pred_in_world, instance[\"pred_category_id\"] - 1)\n",
    "                refined_prediction = np.linalg.inv(T_cam_in_world) @ T_stable_in_world\n",
    "                refined_prediction[0, 3] = raw_prediction[0, 3]\n",
    "                refined_prediction[1, 3] = raw_prediction[1, 3]\n",
    "\n",
    "                self.add_to_results(\"MaskRCNN\", category, raw_prediction, pose_gt, prediction_type=\"raw\")\n",
    "                self.add_to_results(\"MaskRCNN\", category, refined_prediction, pose_gt, prediction_type=\"refined\")\n",
    "\n",
    "    def load_maskrcnn_output(self):\n",
    "        \"\"\"Load Mask R-CNN output from CSV.\"\"\"\n",
    "        maskrcnn_output = {}\n",
    "        with open(self.maskrcnn_csv_path, mode='r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                imgId = int(row[1])\n",
    "                if imgId not in maskrcnn_output:\n",
    "                    maskrcnn_output[imgId] = []\n",
    "                maskrcnn_output[imgId].append({\n",
    "                    \"instance_id\": int(row[0]),\n",
    "                    \"pred_category_id\": int(row[2]),\n",
    "                    \"TP/FP/FN\": row[3],\n",
    "                    \"uv\": eval(row[4])\n",
    "                })\n",
    "        return maskrcnn_output\n",
    "\n",
    "    def crop_image(self, image, uv):\n",
    "        \"\"\"Crop an image based on center coordinates.\"\"\"\n",
    "        return image[\n",
    "            max(uv[1] - self.cropping_size // 2, 0):min(uv[1] + self.cropping_size // 2, image.shape[0]),\n",
    "            max(uv[0] - self.cropping_size // 2, 0):min(uv[0] + self.cropping_size // 2, image.shape[1])\n",
    "        ]\n",
    "\n",
    "    def find_gt_pose(self, instance, imgId):\n",
    "        \"\"\"Find the ground truth pose for a given instance.\"\"\"\n",
    "        for gt_instance in self.pvnet_annotation[str(imgId)]['instances']:\n",
    "            if gt_instance[\"category_id\"] == instance[\"pred_category_id\"] and gt_instance[\"instance_id\"] == instance[\"instance_id\"]:\n",
    "                return np.array(gt_instance[\"pose_in_cam\"])\n",
    "        return None\n",
    "\n",
    "    def print_results(self, results):\n",
    "        for category, stats in results.items():\n",
    "            print(f\"Category: {category}\")\n",
    "            for pred_type, results in stats.items():\n",
    "                if pred_type in [\"valid_count\", \"visualized\"]:\n",
    "                    continue\n",
    "                trans_errors = results[\"translation_error\"]\n",
    "                angular_errors = np.array(results[\"angular_error\"])\n",
    "\n",
    "                if len(trans_errors[\"x\"]) > 0:\n",
    "                    trans_means = {axis: np.mean(np.array(trans_errors[axis]) * 1000) for axis in [\"x\", \"y\", \"z\"]}\n",
    "                    trans_stds = {axis: np.std(np.array(trans_errors[axis]) * 1000) for axis in [\"x\", \"y\", \"z\"]}\n",
    "                    angular_mean = np.mean(angular_errors)\n",
    "                    angular_std = np.std(angular_errors)\n",
    "\n",
    "                    print(f\"  {pred_type.capitalize()} Prediction:\")\n",
    "                    for axis in [\"x\", \"y\", \"z\"]:\n",
    "                        print(f\"    Translation Error ({axis.upper()}): Mean = {trans_means[axis]:.2f} mm, Std = {trans_stds[axis]:.2f} mm\")\n",
    "                    print(f\"    Angular Error (deg): Mean = {angular_mean:.2f}, Std = {angular_std:.2f}\")\n",
    "                    print(f\"    Valid Examples: {stats['valid_count'][pred_type]}\")\n",
    "                else:\n",
    "                    print(f\"  {pred_type.capitalize()} Prediction: No valid instances.\")\n",
    "        \n",
    "    def summarize(self):\n",
    "        \"\"\"Summarize the evaluation results for both GT and Mask R-CNN annotations.\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Summary of Evaluation on GT Cropping\")\n",
    "        print(\"=\" * 70)\n",
    "        self.print_results(self.results[\"GT\"])\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"Summary of Evaluation on Mask-R-CNN Predicted Cropping\")\n",
    "        print(\"=\" * 70)\n",
    "        self.print_results(self.results[\"MaskRCNN\"])\n",
    "        \n",
    "categories = [\"mainshell\", \"topshell\", \"insert_mold\"]\n",
    "evaluator = Evaluator(pvnet_annotation, categories, pvnets, cfgs, pvnet_base_dir, maskrcnn_csv_path)\n",
    "evaluator.evaluate_gt_cropping()\n",
    "evaluator.evaluate_maskrcnn_prediction()\n",
    "evaluator.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check of pose annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Path: /pvnet/data/FIT/end2end/pvnet/0/cropped_rgb/3.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from cobot_pvnet import draw_axis\n",
    "\n",
    "def sanity_check_visualization(pvnet_base_dir, pvnet_annotation, instance_idx=10, crop_size=128):\n",
    "    \"\"\"\n",
    "    Perform a sanity check for visualization of cropped images and overlayed axes.\n",
    "    \n",
    "    Args:\n",
    "    - pvnet_base_dir (str): Base directory of the PVNet dataset.\n",
    "    - pvnet_annotation (dict): Annotation dictionary containing pose and camera information.\n",
    "    - instance_idx (int): Index of the instance to visualize.\n",
    "    - crop_size (int): Size of the crop for visualization.\n",
    "    \"\"\"\n",
    "    # Load the cropped RGB image\n",
    "    rgb_img_path = os.path.join(pvnet_base_dir, pvnet_annotation['0']['instances'][instance_idx]['cropped_rgb'])\n",
    "    print(f\"Image Path: {rgb_img_path}\")\n",
    "    image = cv2.imread(rgb_img_path)\n",
    "    \n",
    "    # Ensure the image is loaded\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found at path: {rgb_img_path}\")\n",
    "    \n",
    "    # Convert the image from BGR to RGB for matplotlib\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Extract transformation and projection details\n",
    "    T = np.array(pvnet_annotation['0']['instances'][instance_idx]['pose_in_cam'])\n",
    "    uv = np.array(pvnet_annotation['0']['instances'][instance_idx]['uv'])\n",
    "    K_cam = np.array(pvnet_annotation['0']['camera_K'])\n",
    "    \n",
    "    # Adjust the intrinsic camera matrix for cropping\n",
    "    K = K_cam.copy()\n",
    "    K[0, 2] += crop_size // 2 - uv[0]\n",
    "    K[1, 2] += crop_size // 2 - uv[1]\n",
    "    \n",
    "    # Draw the axis on the image\n",
    "    img_axis = draw_axis(image_rgb, T[:3, :3], T[:3, 3], K)\n",
    "    \n",
    "    # Display the image with the overlayed axes\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img_axis)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Image with Pose Axis\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "sanity_check_visualization(pvnet_base_dir, pvnet_annotation, instance_idx=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
